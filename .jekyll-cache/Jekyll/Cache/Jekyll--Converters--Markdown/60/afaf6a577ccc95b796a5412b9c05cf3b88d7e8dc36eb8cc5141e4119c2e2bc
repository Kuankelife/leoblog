I""<h2 id="knn文档">KNN文档</h2>

<p>KNN是一种即可用于分类又可用于回归的机器学习算法。对于给定测试样本，基于距离度量找出训练集中与其最靠近的K个训练样本，然后基于这K个“邻居”的信息来进行预测。在分类任务中可使用投票法，选择这K个样本中出现最多的类别标记作为预测结果；在回归任务中可使用平均法，将这K个样本的实值输出标记的平均值作为预测结果。当然还可以基于距离远近程度进行加权平均等方法。</p>

<p><strong>用法</strong>：</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None, **kwargs)[source]
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>参数</strong>：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">n_neighbors</code> : 整数, 可不填 (默认=5)
    <ul>
      <li>默认邻近点的数量</li>
    </ul>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">weights</code> : 字符串或者自定义类型, 可选参数，默认=”uniform”)</p>

    <p>用于预测的权重函数。可选参数如下:</p>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">uniform</code> : 统一的权重. 在每一个邻居区域里的点的权重都是一样的。</li>
      <li><code class="language-plaintext highlighter-rouge">distance</code> : 权重点等于他们距离的倒数。使用此函数，更近的邻居对于所预测的点的影响更大。</li>
      <li><code class="language-plaintext highlighter-rouge">[callable]</code> : 用户可以自定义一个距离函数用来计算权重，此方法接收一个距离的数组，然后返回一个相同形状并且包含权重的数组。</li>
    </ul>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">algorithm</code> : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, 可选参数（默认为 ‘auto’）</p>

    <p>计算最近邻居用的算法：</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ball_tree</code>： 使用算法<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree">BallTree</a></p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">kd_tree</code>： 使用算法<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree">KDTree</a></p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">brute</code>: 使用暴力搜索.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">auto</code>: 会基于传入<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit">fit</a>算法会尝试从训练数据中确定最佳方法</p>
      </li>
    </ul>

    <p>注意 : 如果传入fit方法的输入是稀疏的，将会重载参数设置，直接使用暴力搜索。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">leaf_size</code>:(叶子数量), 整数, 可选参数(默认为 30)</p>

    <p>传入BallTree或者KDTree算法的叶子数量。此参数会影响构建、查询BallTree或者KDTree的速度，以及存储BallTree或者KDTree所需要的内存大小。 此可选参数根据是否是问题所需选择性使用。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">p</code>: 整数, 可选参数(默认为 2)</p>

    <p>用于Minkowski metric（<a href="https://zh.wikipedia.org/wiki/%E9%96%94%E8%80%83%E6%96%AF%E5%9F%BA%E6%99%82%E7%A9%BA">闵可夫斯基空间</a>）的超参数。p = 1, 相当于使用<a href="https://zh.wikipedia.org/wiki/%E6%9B%BC%E5%93%88%E9%A0%93%E8%B7%9D%E9%9B%A2">曼哈顿距离</a> (l1)，p = 2, 相当于使用<a href="https://zh.wikipedia.org/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB">欧几里得距离</a>(l2)  对于任何 p ，使用的是<a href="https://zh.wikipedia.org/wiki/%E9%96%94%E8%80%83%E6%96%AF%E5%9F%BA%E6%99%82%E7%A9%BA">闵可夫斯基空间</a>(l_p)</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">metric</code>:(矩阵), 字符串或者自定义类型, 默认为 ‘minkowski’</p>

    <p>用于树的距离矩阵。默认为<a href="https://zh.wikipedia.org/wiki/%E9%96%94%E8%80%83%E6%96%AF%E5%9F%BA%E6%99%82%E7%A9%BA">闵可夫斯基空间</a>，如果和p=2一块使用相当于使用标准欧几里得矩阵. 所有可用的矩阵列表请查询 DistanceMetric 的文档。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">metric_params</code>:(矩阵参数),字符串或者自定义类型, 可选参数(默认为 None)</p>

    <p>给矩阵方法使用的其他的关键词参数。</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">n_jobs</code>: int, 可选参数(默认为 1)</p>

    <p>用于搜索邻近点的，可并行运行的任务数量。如果为-1, 任务数量设置为CPU核的数量，不会影响<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit">fit</a>方法。</p>
  </li>
</ul>

<p><strong>方法</strong>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>_init__(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None, **kwargs)
</pre></td></tr></tbody></table></code></pre></div></div>
<ul>
  <li><code class="language-plaintext highlighter-rouge">fit(X, y)</code>
    <ul>
      <li>以X为训练数据，y为目标值拟合模型</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">get_params([deep])</code>
    <ul>
      <li>获取拟合器的参数</li>
    </ul>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">kneighbors([X, n_neighbors, return_distance])</code></p>

    <p>找到一个点的k邻域，返回每个点的索引和到相邻点的距离</p>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">n_neighbors</code> : 整数</li>
      <li><code class="language-plaintext highlighter-rouge">return_distance</code>:布尔值，可选。默认值为True,如果为False，则不会返回距离</li>
    </ul>

    <p>返回
      - <code class="language-plaintext highlighter-rouge">dist</code>:表示点的长度的数组，仅当return_distance=True时才出现
      - <code class="language-plaintext highlighter-rouge">ind</code>: 最近点的索引</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">kneighbors_graph([X, n_neighbors, mode])</code>
  为X中的点计算k邻域的(加权)图</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">n_neighbors</code> : 整数</li>
      <li><code class="language-plaintext highlighter-rouge"> mode</code>:{‘ connectivity ‘， ‘ distance ‘}，可选</li>
    </ul>

    <p>返回矩阵类型:‘connectivity’ 将返回带1和0的连通性矩阵，‘distance’点与点之间的欧氏距离</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">predict(X)</code>：
    <ul>
      <li>预测X的类别</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">predict_log_proba(X)</code>:
    <ul>
      <li>预测X为各个类别的概率对数值。</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">predict_proba(X)</code>:
    <ul>
      <li>预测X为各个类别的概率值。</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">score(X, y[, sample_weight])</code>
    <ul>
      <li>返回给定测试数据的平均准确度
        <ul>
          <li><code class="language-plaintext highlighter-rouge">sample_weight</code>:类数组，shape = [n_samples]，可选</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">set_params(**params)</code>
    <ul>
      <li>设置此估计器的参数</li>
    </ul>
  </li>
</ul>

<p>附上<a href="http://sklearn.apachecn.org/#/">scikit-learn (sklearn) 官方文档中文版</a></p>
:ET